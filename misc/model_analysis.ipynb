{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of LSTM forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import HourLocator, DateFormatter\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_ids_training = [\n",
    "    \"site_0030\",\n",
    "    \"site_0027\",\n",
    "    \"site_0022\",\n",
    "    \"site_0024\",\n",
    "    \"site_0009\",\n",
    "    \"site_0005\",\n",
    "    \"site_0018\",\n",
    "    \"site_0006\",\n",
    "    \"site_0017\",\n",
    "    \"site_0028\",\n",
    "    \"site_0012\"\n",
    "]\n",
    "\n",
    "site_ids_independent = [\n",
    "    \"site_0026\", # orientation 1, independent population\n",
    "    \"site_0021\", # orientation 4, independent population\n",
    "]\n",
    "\n",
    "site_ids_prediction = site_ids_training + site_ids_independent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_prediction_power = pd.read_csv('../data/shared_data/centralized/prediction/all/prediction_all_power.csv')\n",
    "df_prediction_acc_energy = pd.read_csv('../data/shared_data/centralized/prediction/all/prediction_all_acc_energy.csv')\n",
    "\n",
    "df_prediction_power['time'] = pd.to_datetime(df_prediction_power['time'])\n",
    "df_prediction_power['index'] = df_prediction_power['time']\n",
    "df_prediction_power.set_index('index', inplace=True)\n",
    "df_prediction_power = df_prediction_power.sort_values(by='time')\n",
    "\n",
    "df_prediction_acc_energy['time'] = pd.to_datetime(df_prediction_acc_energy['time'])\n",
    "df_prediction_acc_energy['index'] = df_prediction_acc_energy['time']\n",
    "df_prediction_acc_energy.set_index('index', inplace=True)\n",
    "df_prediction_acc_energy = df_prediction_acc_energy.sort_values(by='time')\n",
    "\n",
    "df_prediction_power_centralized_all = df_prediction_power\n",
    "df_prediction_acc_energy_centralized_all = df_prediction_acc_energy\n",
    "\n",
    "CENTRALIZED_ALL = True\n",
    "CENTRALIZED_CONTINUAL = False\n",
    "FEDERATED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_power = pd.read_csv('../data/shared_data/centralized/prediction/continual/prediction_all_power.csv')\n",
    "df_prediction_acc_energy = pd.read_csv('../data/shared_data/centralized/prediction/continual/prediction_all_acc_energy.csv')\n",
    "\n",
    "df_prediction_power['time'] = pd.to_datetime(df_prediction_power['time'])\n",
    "df_prediction_power['index'] = df_prediction_power['time']\n",
    "df_prediction_power.set_index('index', inplace=True)\n",
    "df_prediction_power = df_prediction_power.sort_values(by='time')\n",
    "\n",
    "df_prediction_acc_energy['time'] = pd.to_datetime(df_prediction_acc_energy['time'])\n",
    "df_prediction_acc_energy['index'] = df_prediction_acc_energy['time']\n",
    "df_prediction_acc_energy.set_index('index', inplace=True)\n",
    "df_prediction_acc_energy = df_prediction_acc_energy.sort_values(by='time')\n",
    "\n",
    "df_prediction_power_centralized_continual = df_prediction_power\n",
    "df_prediction_acc_energy_centralized_continual = df_prediction_acc_energy\n",
    "\n",
    "CENTRALIZED_ALL = False\n",
    "CENTRALIZED_CONTINUAL = True\n",
    "FEDERATED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_power = pd.read_csv('../data/shared_data/federated/prediction/prediction_all_power.csv')\n",
    "df_prediction_acc_energy = pd.read_csv('../data/shared_data/federated/prediction/prediction_all_acc_energy.csv')\n",
    "\n",
    "df_prediction_power['time'] = pd.to_datetime(df_prediction_power['time'])\n",
    "df_prediction_power['index'] = df_prediction_power['time']\n",
    "df_prediction_power.set_index('index', inplace=True)\n",
    "df_prediction_power = df_prediction_power.sort_values(by='time')\n",
    "\n",
    "df_prediction_acc_energy['time'] = pd.to_datetime(df_prediction_acc_energy['time'])\n",
    "df_prediction_acc_energy['index'] = df_prediction_acc_energy['time']\n",
    "df_prediction_acc_energy.set_index('index', inplace=True)\n",
    "df_prediction_acc_energy = df_prediction_acc_energy.sort_values(by='time')\n",
    "\n",
    "df_prediction_power_federated = df_prediction_power\n",
    "df_prediction_acc_energy_federated = df_prediction_acc_energy\n",
    "\n",
    "CENTRALIZED_ALL = False\n",
    "CENTRALIZED_CONTINUAL = False\n",
    "FEDERATED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_error(data, key, mult, desc):\n",
    "    data_day = data[(data['time'].dt.time >= pd.to_datetime('06:00').time()) & \n",
    "                                    (data['time'].dt.time <= pd.to_datetime('21:00').time())]\n",
    "    \n",
    "    error = ((abs((data[key] - data['actual'])) / (data['kwp'] * mult)) * 100)\n",
    "    \n",
    "    error_day = (((abs(data_day[key] - data_day['actual'])) / (data_day['kwp'] * mult)) * 100)\n",
    "\n",
    "    mean_error = error.mean()\n",
    "    mean_error_day = error_day.mean()\n",
    "\n",
    "    median_error = error.median()\n",
    "    median_error_day = error_day.median()\n",
    "\n",
    "    max_error = error.max()\n",
    "\n",
    "\n",
    "    print(f'Mean {mean_error_day:.2f}% Median: {median_error_day:.2f}% (06:00-21:00) | Mean: {mean_error:.2f}% Median: {median_error:.2f}% | Max: {max_error:.2f}%    --- Error for {desc} {key}')\n",
    "\n",
    "for key in ['local']:\n",
    "    key = f'predicted_{key}'\n",
    "\n",
    "    show_error(df_prediction_power_centralized_all, key, 1000, \"Power (Centralized (All))\")\n",
    "    show_error(df_prediction_acc_energy_centralized_all, key, 1000 * 12, \"Acc. Energy (Centralized (All))\")\n",
    "\n",
    "for key in ['local']:\n",
    "    key = f'predicted_{key}'\n",
    "\n",
    "    show_error(df_prediction_power_centralized_continual, key, 1000, \"Power (Centralized (Continual))\")\n",
    "    show_error(df_prediction_acc_energy_centralized_continual, key, 1000 * 12, \"Acc. Energy (Centralized (Continual))\")\n",
    "\n",
    "for key in [ 'global', 'cluster_location', 'cluster_orientation', 'local']:\n",
    "    key = f'predicted_{key}'\n",
    "\n",
    "    show_error(df_prediction_power_federated, key, 1000, \"Power (Federated)\")\n",
    "    show_error(df_prediction_acc_energy_federated, key, 1000 * 12, \"Acc. Energy (Federated)\")    \n",
    "\n",
    "    df_prediction_power_federated_independent = df_prediction_power_federated[df_prediction_power_federated['site_id'].isin(site_ids_independent)]\n",
    "    df_prediction_acc_energy_federated_independent = df_prediction_acc_energy_federated[df_prediction_acc_energy_federated['site_id'].isin(site_ids_independent)]\n",
    "\n",
    "    show_error(df_prediction_power_federated_independent, key, 1000, \"Power (Federated Independent)\")\n",
    "    show_error(df_prediction_acc_energy_federated_independent, key, 1000 * 12, \"Acc. Energy (Federated Independent)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: all charts are scaled to 1\n",
    "\n",
    "SAVE_PLOTS = True\n",
    "SHOW_WEATHER = False\n",
    "\n",
    "def show_combined_plots(model, plot_info, color, week_data_power, week_data_energy, kwp, max_energy, save_path):\n",
    "    # Reduced height further\n",
    "    fig = plt.figure(figsize=(20, 9))\n",
    "    \n",
    "    key = f'predicted_{model}'\n",
    "    round = week_data_power[f'{model}_model_round'].iloc[0]\n",
    "    \n",
    "    # Power Plot (top left)\n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    ax1.plot(week_data_power['time'], week_data_power['actual'] / (kwp * 1000), \n",
    "             label='Actual', linestyle='-', color='black', linewidth=1)\n",
    "    ax1.plot(week_data_power['time'], week_data_power[key] / (kwp * 1000), \n",
    "             label=f'Predicted (Training Round {round})', linestyle='--', color=color, linewidth=1)\n",
    "    \n",
    "    if SHOW_WEATHER:\n",
    "        ax1.plot(week_data_power['time'], week_data_power['solar_rad'] / 1000, label='Solar Rad', linestyle='--', color='grey', linewidth=0.5)\n",
    "        ax1.plot(week_data_power['time'], week_data_power['clouds'] / 100, label='Clouds', linestyle='--', color='green', linewidth=0.5)\n",
    "        ax1.plot(week_data_power['time'], week_data_power['snow_depth'] / 1200, label='Snow Depth', linestyle='--', color='red', linewidth=0.5)\n",
    "        ax1.plot(week_data_power['time'], week_data_power['precip'] / 15, label='Precip', linestyle='--', color='blue', linewidth=0.5)\n",
    "    \n",
    "    ax1.set_ylim(0, 1.1)\n",
    "    ax1.set_title(f'Power Output - {plot_info}')\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel(f'Power (1 = {kwp}kW)')\n",
    "    ax1.xaxis.set_major_locator(HourLocator(byhour=[12]))  # Show noon (12:00)\n",
    "    ax1.xaxis.set_major_formatter(DateFormatter('%y-%m-%d\\n12:00'))  # Format as yy-mm-dd 12\n",
    "    ax1.tick_params(axis='x', rotation=0)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Energy Plot (top right)\n",
    "    ax2 = plt.subplot(2, 2, 2)\n",
    "    ax2.plot(week_data_energy['time'], week_data_energy['actual'] / max_energy, \n",
    "             label='Actual', linestyle='-', color='black', linewidth=1)\n",
    "    ax2.plot(week_data_energy['time'], week_data_energy[key] / max_energy, \n",
    "             label=f'Predicted (Training Round {round})', linestyle='--', color=color, linewidth=1)\n",
    "    \n",
    "    ax2.set_ylim(0, 1.1)\n",
    "    ax2.set_title(f'Energy Output - {plot_info}')\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel(f'Energy (1 = {max_energy/1000:.1f}kWh)')\n",
    "    ax2.xaxis.set_major_locator(HourLocator(byhour=[12]))  # Show noon (12:00)\n",
    "    ax2.xaxis.set_major_formatter(DateFormatter('%y-%m-%d\\n12:00'))  # Format as yy-mm-dd 12\n",
    "    ax2.tick_params(axis='x', rotation=0)\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Power Error Plot (bottom left)\n",
    "    ax3 = plt.subplot(2, 2, 3)\n",
    "    power_error = (abs((week_data_power[key] - week_data_power['actual'])) / (kwp * 1000)) * 100\n",
    "    \n",
    "    # Filter data between 06:00 and 21:00 for power\n",
    "    week_data_power_day = week_data_power[\n",
    "        (week_data_power['time'].dt.time >= pd.to_datetime('06:00').time()) & \n",
    "        (week_data_power['time'].dt.time <= pd.to_datetime('21:00').time())\n",
    "    ]\n",
    "    power_mean_error_day = ((abs(week_data_power_day[key] - week_data_power_day['actual'])) / (kwp * 1000) * 100).mean()\n",
    "    power_mean_error = power_error.mean()\n",
    "    \n",
    "    ax3.plot(week_data_power['time'], power_error, \n",
    "             label=f'Power Error (Training Round {round})', linestyle='--', color=color, linewidth=0.5)\n",
    "    ax3.set_ylim(0, 110)\n",
    "    ax3.set_title(f'Power Error - {plot_info}')\n",
    "    ax3.set_xlabel('Time')\n",
    "    ax3.set_ylabel('Error (%)')\n",
    "    ax3.xaxis.set_major_locator(HourLocator(byhour=[12]))  # Show noon (12:00)\n",
    "    ax3.xaxis.set_major_formatter(DateFormatter('%y-%m-%d\\n12:00'))  # Format as yy-mm-dd 12\n",
    "    ax3.tick_params(axis='x', rotation=0)\n",
    "    ax3.legend()\n",
    "    ax3.text(0.02, 0.95, f'Mean Error Total: {power_mean_error:.2f}%', \n",
    "             transform=ax3.transAxes, fontsize=10, verticalalignment='top', \n",
    "             bbox=dict(facecolor='white', alpha=0.8))\n",
    "    ax3.text(0.02, 0.85, f'Mean Error (06:00-21:00): {power_mean_error_day:.2f}%', \n",
    "             transform=ax3.transAxes, fontsize=10, verticalalignment='top', \n",
    "             bbox=dict(facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Energy Error Plot (bottom right)\n",
    "    ax4 = plt.subplot(2, 2, 4)\n",
    "    energy_error = (abs((week_data_energy[key] - week_data_energy['actual'])) / max_energy) * 100\n",
    "    \n",
    "    # Filter data between 06:00 and 21:00 for energy\n",
    "    week_data_energy_day = week_data_energy[\n",
    "        (week_data_energy['time'].dt.time >= pd.to_datetime('06:00').time()) & \n",
    "        (week_data_energy['time'].dt.time <= pd.to_datetime('21:00').time())\n",
    "    ]\n",
    "    energy_mean_error_day = ((abs(week_data_energy_day[key] - week_data_energy_day['actual'])) / max_energy * 100).mean()\n",
    "    energy_mean_error = energy_error.mean()\n",
    "    \n",
    "    ax4.plot(week_data_energy['time'], energy_error, \n",
    "             label=f'Energy Error (Training Round {round})', linestyle='--', color=color, linewidth=0.5)\n",
    "    ax4.set_ylim(0, 110)\n",
    "    ax4.set_title(f'Energy Error - {plot_info}')\n",
    "    ax4.set_xlabel('Time')\n",
    "    ax4.set_ylabel('Error (%)')\n",
    "    ax4.xaxis.set_major_locator(HourLocator(byhour=[12]))  # Show noon (12:00)\n",
    "    ax4.xaxis.set_major_formatter(DateFormatter('%y-%m-%d\\n12:00'))  # Format as yy-mm-dd 12\n",
    "    ax4.tick_params(axis='x', rotation=0)\n",
    "    ax4.legend()\n",
    "    ax4.text(0.02, 0.95, f'Mean Error Total: {energy_mean_error:.2f}%', \n",
    "             transform=ax4.transAxes, fontsize=10, verticalalignment='top', \n",
    "             bbox=dict(facecolor='white', alpha=0.8))\n",
    "    ax4.text(0.02, 0.85, f'Mean Error (06:00-21:00): {energy_mean_error_day:.2f}%', \n",
    "             transform=ax4.transAxes, fontsize=10, verticalalignment='top', \n",
    "             bbox=dict(facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout(h_pad=2, w_pad=3)\n",
    "    \n",
    "    if SAVE_PLOTS:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "df_prediction_power['week'] = df_prediction_power['time'].dt.to_period('W')\n",
    "df_prediction_acc_energy['week'] = df_prediction_acc_energy['time'].dt.to_period('W')\n",
    "\n",
    "df_prediction_power = df_prediction_power.sort_values(by='time')\n",
    "df_prediction_acc_energy = df_prediction_acc_energy.sort_values(by='time')\n",
    "\n",
    "unique_weeks = df_prediction_power['week'].unique()\n",
    "\n",
    "grouped_data_power = df_prediction_power.groupby(['week', 'site_id'])\n",
    "grouped_data_acc_energy = df_prediction_acc_energy.groupby(['week', 'site_id'])\n",
    "\n",
    "for (week, site_id), _ in grouped_data_power:\n",
    "    kwp = df_prediction_power.loc[df_prediction_power['site_id'] == site_id, 'kwp'].iloc[0]\n",
    "    max_actual_energy = kwp * 12 * 1000\n",
    "    \n",
    "    week_data_power = grouped_data_power.get_group((week, site_id))\n",
    "    week_data_acc_energy = grouped_data_acc_energy.get_group((week, site_id))\n",
    "    \n",
    "    independent_population = not (site_id in site_ids_training)\n",
    "    independent_population_info = ' [INDEPENDENT POPULATION]' if independent_population else ''\n",
    "    \n",
    "    if CENTRALIZED_ALL:\n",
    "        base_path = '../data/plots/centralized/all'\n",
    "    elif CENTRALIZED_CONTINUAL:\n",
    "        base_path = '../data/plots/centralized/continual'\n",
    "    elif FEDERATED:\n",
    "        base_path = '../data/plots/federated'\n",
    "\n",
    "    # ensure path exists\n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "\n",
    "    plot_info = f'Site {site_id}{independent_population_info}'\n",
    "    week_path = str(week).replace('/', '_')\n",
    "    base_path = f'{base_path}/{site_id}_week_{week_path}'\n",
    "    \n",
    "    if FEDERATED:\n",
    "        show_combined_plots('local', f'{plot_info} - Local', 'red', \n",
    "                          week_data_power, week_data_acc_energy, kwp, max_actual_energy,\n",
    "                          f'{base_path}_local_combined.png')\n",
    "        \n",
    "        show_combined_plots('cluster_location', f'{plot_info} - Cluster Location', 'green',\n",
    "                          week_data_power, week_data_acc_energy, kwp, max_actual_energy,\n",
    "                          f'{base_path}_cluster_location_combined.png')\n",
    "        \n",
    "        show_combined_plots('cluster_orientation', f'{plot_info} - Cluster Orientation', 'purple',\n",
    "                          week_data_power, week_data_acc_energy, kwp, max_actual_energy,\n",
    "                          f'{base_path}_cluster_orientation_combined.png')\n",
    "        \n",
    "        show_combined_plots('global', f'{plot_info} - Global', 'blue',\n",
    "                          week_data_power, week_data_acc_energy, kwp, max_actual_energy,\n",
    "                          f'{base_path}_global_combined.png')\n",
    "        \n",
    "    elif CENTRALIZED_ALL:\n",
    "        show_combined_plots('local', f'{plot_info} - Centralized (All)', 'turquoise',\n",
    "                          week_data_power, week_data_acc_energy, kwp, max_actual_energy,\n",
    "                          f'{base_path}_local_combined.png')\n",
    "        \n",
    "    elif CENTRALIZED_CONTINUAL:\n",
    "        show_combined_plots('local', f'{plot_info} - Centralized (Continual)', 'aquamarine',\n",
    "                          week_data_power, week_data_acc_energy, kwp, max_actual_energy,\n",
    "                          f'{base_path}_local_combined.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_acc_energy = pd.read_csv('../data/shared_data/federated/training/training_all_acc_energy.csv')\n",
    "\n",
    "df_prediction_acc_energy['time'] = pd.to_datetime(df_prediction_acc_energy['time'])\n",
    "df_prediction_acc_energy['index'] = df_prediction_acc_energy['time']\n",
    "df_prediction_acc_energy['date'] = df_prediction_acc_energy['time'].dt.date\n",
    "df_prediction_acc_energy.set_index('index', inplace=True)\n",
    "df_prediction_acc_energy = df_prediction_acc_energy.sort_values(by='time')\n",
    "\n",
    "df_federated = df_prediction_acc_energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_acc_energy = pd.read_csv('../data/shared_data/centralized/training/continual/training_all_acc_energy.csv')\n",
    "\n",
    "df_prediction_acc_energy['time'] = pd.to_datetime(df_prediction_acc_energy['time'])\n",
    "df_prediction_acc_energy['index'] = df_prediction_acc_energy['time']\n",
    "df_prediction_acc_energy['date'] = df_prediction_acc_energy['time'].dt.date\n",
    "df_prediction_acc_energy.set_index('index', inplace=True)\n",
    "df_prediction_acc_energy = df_prediction_acc_energy.sort_values(by='time')\n",
    "\n",
    "df_centralized_continual = df_prediction_acc_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_acc_energy = pd.read_csv('../data/shared_data/centralized/training/all/training_all_acc_energy.csv')\n",
    "\n",
    "df_prediction_acc_energy['time'] = pd.to_datetime(df_prediction_acc_energy['time'])\n",
    "df_prediction_acc_energy['index'] = df_prediction_acc_energy['time']\n",
    "df_prediction_acc_energy['date'] = df_prediction_acc_energy['time'].dt.date\n",
    "df_prediction_acc_energy.set_index('index', inplace=True)\n",
    "df_prediction_acc_energy = df_prediction_acc_energy.sort_values(by='time')\n",
    "\n",
    "df_centralized_all = df_prediction_acc_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_production_data(df, prediction_cols):\n",
    "    df.info()\n",
    "    df = df.groupby(['site_id', 'date']).last().reset_index()\n",
    "    #df.info()\n",
    "\n",
    "\n",
    "    def calculate_max_power(row):\n",
    "        return 12 * 1000 * row['kwp']  # 12h * 1000W/kW * system size in kWp\n",
    "\n",
    "    # Add max power column\n",
    "    df['max_energy'] = df.apply(calculate_max_power, axis=1)\n",
    "    \n",
    "    error_cols = []\n",
    "    training_run_col = []\n",
    "    predicted_cols = []\n",
    "\n",
    "\n",
    "    for col in prediction_cols:\n",
    "        predicted_col = f'predicted_{col}'\n",
    "        error_col = f'{col}_error'\n",
    "        error_cols.append(error_col)\n",
    "        training_run_col.append(f'{col}_model_round')\n",
    "        predicted_cols.append(predicted_col)\n",
    "        df[error_col] = abs(df[predicted_col] - df['actual']) / df['max_energy'] * 100\n",
    "\n",
    "    columns_to_keep = ['site_id', 'date'] + error_cols + training_run_col + ['max_energy']\n",
    "\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_federated_filtered = prepare_production_data(df_federated, ['local', 'cluster_location', 'cluster_orientation', 'global'])\n",
    "df_centralized_continual_filtered = prepare_production_data(df_centralized_continual, ['local'])\n",
    "df_centralized_all_filtered = prepare_production_data(df_centralized_all, ['local'])\n",
    "\n",
    "df_centralized_continual_filtered.rename(columns={'local_error': 'centralized_continual_error', 'local_model_round': 'centralized_continual_model_round'}, inplace=True)\n",
    "df_centralized_all_filtered.rename(columns={'local_error': 'centralized_all_error', 'local_model_round': 'centralized_all_model_round'}, inplace=True)\n",
    "\n",
    "df_combined = df_federated_filtered.merge(df_centralized_continual_filtered, on=['site_id', 'date', 'max_energy'])\n",
    "df_combined = df_combined.merge(df_centralized_all_filtered, on=['site_id', 'date', 'max_energy'])\n",
    "\n",
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['best_model_federated'] = df_combined[['local_error', 'cluster_location_error', 'cluster_orientation_error', 'global_error', 'centralized_continual_error']].idxmin(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_best_model_errors(df, site_id):\n",
    "    site_data = df[df['site_id'] == site_id].copy()\n",
    "    site_data['date'] = pd.to_datetime(site_data['date'])\n",
    "    \n",
    "    color_map = {\n",
    "        'local': 'red',\n",
    "        'cluster_location': 'green',\n",
    "        'cluster_orientation': 'purple',\n",
    "        'global': 'blue',\n",
    "        'centralized_continual': 'aquamarine',\n",
    "        # 'centralized_all': 'turquoise'\n",
    "    }\n",
    "    \n",
    "    error_columns = ['local_error', 'cluster_location_error', \n",
    "                    'cluster_orientation_error', 'global_error', \n",
    "                    'centralized_continual_error'] # , 'centralized_all_error']\n",
    "    \n",
    "    round_columns = ['local_model_round', 'cluster_location_model_round',\n",
    "                    'cluster_orientation_model_round', 'global_model_round',\n",
    "                    'centralized_continual_model_round'] #, 'centralized_all_model_round']\n",
    "    \n",
    "    bar_colors = []\n",
    "    min_errors = []\n",
    "    valid_dates = []\n",
    "    x_positions = []\n",
    "    rounds = []\n",
    "    position = 0\n",
    "    \n",
    "    for idx, row in site_data.iterrows():\n",
    "        errors = [row[col] for col in error_columns]\n",
    "        valid_errors = [e for e in errors if not pd.isna(e)]\n",
    "        \n",
    "        if valid_errors:\n",
    "            min_error = min(valid_errors)\n",
    "            min_errors.append(min_error)\n",
    "            valid_dates.append(row['date'])\n",
    "            x_positions.append(position)\n",
    "            \n",
    "            # Find which model had minimum error and get its round\n",
    "            model_name = None\n",
    "            model_round = None\n",
    "            for error_col, round_col, error in zip(error_columns, round_columns, errors):\n",
    "                if error == min_error:\n",
    "                    model_name = error_col.replace('_error', '')\n",
    "                    model_round = row[round_col]\n",
    "                    break\n",
    "            \n",
    "            rounds.append(model_round)\n",
    "            bar_colors.append(color_map[model_name])\n",
    "            position += 1\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    bars = plt.bar(x_positions, min_errors, color=bar_colors)\n",
    "    \n",
    "    # Add round numbers on top of bars with smaller font size and rotated text\n",
    "    for idx, rect in enumerate(bars):\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width()/2., height,\n",
    "                f'{rounds[idx]}',\n",
    "                ha='center', va='bottom', fontsize=6, rotation=45)  # Smaller font size and rotated\n",
    "    \n",
    "    # Clean title and labels for better readability\n",
    "    plot_title = f'Best Model Errors Over Time for Site {site_id}'.title()  # Capitalize for title case\n",
    "    plt.title(plot_title)\n",
    "    \n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Error (%)')\n",
    "    plt.ylim(0, 50)\n",
    "\n",
    "    # Choose every 3rd date for the x-axis ticks\n",
    "    tick_interval = 3  # Change this number to adjust the interval (e.g., every 3rd date)\n",
    "    selected_positions = x_positions[::tick_interval]\n",
    "    selected_dates = [valid_dates[i] for i in range(0, len(valid_dates), tick_interval)]\n",
    "\n",
    "    # Format the dates for the x-axis\n",
    "    plt.xticks(selected_positions, [date.strftime('%Y-%m-%d') for date in selected_dates], rotation=45, ha='right')\n",
    "\n",
    "    # Adjust the layout to ensure labels fit\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Add a legend with a more readable format\n",
    "    legend_elements = [plt.Rectangle((0,0),1,1, color=color) \n",
    "                      for color in color_map.values()]\n",
    "    plt.legend(legend_elements, [key.replace('_', ' ').title() for key in color_map.keys()], \n",
    "              title='Best Performing Model')\n",
    "    \n",
    "    return plt\n",
    "\n",
    "\n",
    "# ensure path exists\n",
    "path = '../data/plots/best_model_errors'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "for site_id in site_ids_training:\n",
    "    plot = plot_best_model_errors(df_combined, site_id)\n",
    "    plot_path = f'{path}/{site_id}_best_model_errors.png'\n",
    "    plot.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
